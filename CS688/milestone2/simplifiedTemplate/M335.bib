
@article{Linhart2014,
  author  = {Jean Marie Linhart},
  title   = {Teaching Writing and Communication in a Mathematical Modeling Course},
  journal = {PRIMUS},
  volume  = {24},
  number  = {7},
  pages   = {594-607},
  year    = {2014}
}


@book{higham1998handbook,
  title     = {Handbook of writing for the mathematical sciences},
  author    = {Higham, N.J.},
  year      = {1998},
  publisher = {Society for Industrial Mathematics}
}
@misc{vihart,
  title     = {Pi is (still) wrong},
  author    = {Hart, V. I.},
  year      = {2011},
  publisher = {YouTube},
  url       = {http://vihart.com/blog/pi-is-still-wrong/}
}

@misc{taumanifesto,
  title  = {The {T}au {M}anifesto},
  author = {Michael Hartl},
  year   = {2010},
  url    = {http://tauday.com/}
}

@misc{chaoswiki,
  title  = {Chaos {T}heory},
  author = {Wikipedia},
  year   = {2012},
  url    = {http://en.wikipedia.org/Chaos_theory}
}
@misc{fractalwiki,
  title  = {Fractal},
  author = {Wikipedia},
  year   = {2012},
  url    = {http://en.wikipedia.org/Fractal}
}

@article{Linhart2008,
  author  = {J. M. Linhart},
  title   = {Algorithm 885: Computing the logarithm of the normal distribution.},
  journal = {ACM Transactions on Mathematical Software},
  pages   = {Article 20},
  volume  = 35,
  year    = 2008
}


@article{FischlerM.A1973TRaM,
  abstract  = {The primary problem dealt with in this paper is the following. Given some description of a visual object, find that object in an actual photograph. Part of the solution to this problem is the specification of a descriptive scheme, and a metric on which to base the decision of "goodness" of matching or detection.},
  author    = {Fischler, M.A and Elschlager, R.A},
  issn      = {0018-9340},
  journal   = {IEEE transactions on computers},
  keywords  = {Dynamic programming ; heuristic optimization ; picture description ; picture matching ; picture processing ; representation},
  language  = {eng},
  number    = {1},
  pages     = {67-92},
  publisher = {IEEE},
  title     = {The Representation and Matching of Pictorial Structures},
  volume    = {C-22},
  year      = {1973}
}

@misc{wang20193d,
  title         = {3D Human Pose Machines with Self-supervised Learning},
  author        = {Keze Wang and Liang Lin and Chenhan Jiang and Chen Qian and Pengxu Wei},
  year          = {2019},
  eprint        = {1901.03798},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{guler2018densepose,
  title         = {DensePose: Dense Human Pose Estimation In The Wild},
  author        = {Rıza Alp Güler and Natalia Neverova and Iasonas Kokkinos},
  year          = {2018},
  eprint        = {1802.00434},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{papandreou2018personlab,
  title         = {PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model},
  author        = {George Papandreou and Tyler Zhu and Liang-Chieh Chen and Spyros Gidaris and Jonathan Tompson and Kevin Murphy},
  year          = {2018},
  eprint        = {1803.08225},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{StollC2011Famt,
  abstract  = {We present an approach for modeling the human body by Sums of spatial Gaussians (SoG), allowing us to perform fast and high-quality markerless motion capture from multi-view video sequences. The SoG model is equipped with a color model to represent the shape and appearance of the human and can be reconstructed from a sparse set of images. Similar to the human body, we also represent the image domain as SoG that models color consistent image blobs. Based on the SoG models of the image and the human body, we introduce a novel continuous and differentiable model-to-image similarity measure that can be used to estimate the skeletal motion of a human at 5-15 frames per second even for many camera views. In our experiments, we show that our method, which does not rely on silhouettes or training data, offers an good balance between accuracy and computational cost.},
  author    = {Stoll, C and Hasler, N and Gall, J and Seidel, H and Theobalt, C},
  booktitle = {2011 International Conference on Computer Vision},
  isbn      = {9781457711015},
  issn      = {1550-5499},
  keywords  = {Cameras ; Humans ; Image color analysis ; Joints ; Solid modeling ; Three dimensional displays},
  language  = {eng},
  pages     = {951-958},
  publisher = {IEEE},
  title     = {Fast articulated motion tracking using a sums of Gaussians body model},
  year      = {2011}
}

@article{Diego-MasJoseAntonio2014UKsi,
  abstract  = {This paper examines the potential use of Kinect™ range sensor in observational methods for assessing postural loads. Range sensors can detect the position of the joints at high sampling rates without attaching sensors or markers directly to the subject under study. First, a computerized OWAS ergonomic assessment system was implemented to permit the data acquisition from Kinect™ and data processing in order to identify the risk level of each recorded postures. Output data were compared with the results provided by human observers, and were used to determine the influence of the sensor view angle relative to the worker. The tests show high inter-method agreement in the classification of risk categories (Proportion agreement index = 0.89 κ = 0.83) when the tracked subject is facing the sensor. The camera's point of view relative to the position of the tracked subject significantly affects the correct classification of the postures. Although the results are promising, some aspects involved in the use of low-cost range sensors should be further studied for their use in real environments.
•This paper examines the potential use of Kinect™ range sensors in observational methods for assessing postural loads.•The results obtained by human observers are compared with those obtained by the sensor.•The influence of the position of the sensor with respect to the tracked user is analyzed.•High agreement exists between human observers and the sensor when the tracked subject stands facing the sensor.•The orientation of the sensor with respect to the worker affects the sensor's ability to identify the body positions.},
  author    = {Diego-Mas, Jose Antonio and Alcaide-Marzal, Jorge},
  address   = {OXFORD},
  copyright = {2013 Elsevier Ltd and The Ergonomics Society},
  issn      = {0003-6870},
  journal   = {Applied ergonomics},
  keywords  = {Analysis ; Applied physiology ; Biological and medical sciences ; Engineering ; Engineering, Industrial ; Ergonomics ; Ergonomics - instrumentation ; Ergonomics - methods ; Ergonomics. Human factors ; Ergonomics. Work place. Occupational physiology ; Fundamental and applied biological sciences. Psychology ; Human physiology applied to population studies and life conditions. Human ecophysiology ; Humans ; Kinect ; Medical sciences ; Methods ; Movement - physiology ; Occupational psychology ; OWAS ; Posture - physiology ; Psychology ; Psychology, Applied ; Psychology. Psychoanalysis. Psychiatry ; Psychology. Psychophysiology ; Science & Technology ; Sensors ; Social Sciences ; Technology ; Weight-Bearing - physiology ; Workplace},
  language  = {eng},
  number    = {4},
  pages     = {976-985},
  publisher = {Elsevier Ltd},
  title     = {Using Kinect™ sensor in observational methods for assessing postures at work},
  volume    = {45},
  year      = {2014}
}



@misc{tompson2014joint,
  title         = {Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation},
  author        = {Jonathan Tompson and Arjun Jain and Yann LeCun and Christoph Bregler},
  year          = {2014},
  eprint        = {1406.2984},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{Toshev_2014_CVPR,
  author    = {Toshev, Alexander and Szegedy, Christian},
  title     = {DeepPose: Human Pose Estimation via Deep Neural Networks},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {June},
  year      = {2014}
}

@article{LiuZhao2015Asoh,
  abstract  = {•Summarization of methods on human pose estimation in recent years.•Conclusion of the traditional human pose estimation methods.•Illustrated based on a two-stage framework.•Comprehensive comparisons are given based on the open source methods.
Estimating human pose from videos and image sequences is not only an important computer vision problem, but also plays very critical role in many real-world applications. Main challenges for human pose estimation are variation of body poses, complicated background and depth ambiguities. To solve these problems, considerable research efforts have been devoted to the related fields. In this survey, we focus our attention on the recent advances in vision-based human pose estimation. We first present a general framework of human pose estimation, and then go through the latest technical progress on each stage. Finally, we discuss the limitations of the existing approaches and foresee the future directions to be explored.},
  author    = {Liu, Zhao and Zhu, Jianke and Bu, Jiajun and Chen, Chun},
  copyright = {2015 Elsevier Inc.},
  issn      = {1047-3203},
  journal   = {Journal of visual communication and image representation},
  keywords  = {Appearance models ; Articulated object detection ; Body parts parsing ; Computer science ; Feature Extraction ; Human pose estimation ; Machine vision ; Methods ; Motion capture ; Structure models ; Survey ; Surveys},
  language  = {eng},
  pages     = {10-19},
  publisher = {Elsevier Inc},
  title     = {A survey of human pose estimation: The body parts parsing based methods},
  volume    = {32},
  year      = {2015}
}

@article{TompsonJonathan2014JToa,
  abstract  = {This paper proposes a new hybrid architecture that consists of a deep
Convolutional Network and a Markov Random Field. We show how this architecture
is successfully applied to the challenging problem of articulated human pose
estimation in monocular images. The architecture can exploit structural domain
constraints such as geometric relationships between body joint locations. We
show that joint training of these two model paradigms improves performance and
allows us to significantly outperform existing state-of-the-art techniques.},
  author    = {Tompson, Jonathan and Jain, Arjun and LeCun, Yann and Bregler, Christoph},
  copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
  keywords  = {Computer Science - Computer Vision and Pattern Recognition},
  language  = {eng},
  title     = {Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation},
  year      = {2014}
}

@article{ChenXianjie2014APEb,
  abstract  = {We present a method for estimating articulated human pose from a single
static image based on a graphical model with novel pairwise relations that make
adaptive use of local image measurements. More precisely, we specify a
graphical model for human pose which exploits the fact the local image
measurements can be used both to detect parts (or joints) and also to predict
the spatial relationships between them (Image Dependent Pairwise Relations).
These spatial relationships are represented by a mixture model. We use Deep
Convolutional Neural Networks (DCNNs) to learn conditional probabilities for
the presence of parts and their spatial relationships within image patches.
Hence our model combines the representational flexibility of graphical models
with the efficiency and statistical power of DCNNs. Our method significantly
outperforms the state of the art methods on the LSP and FLIC datasets and also
performs very well on the Buffy dataset without any training.},
  author    = {Chen, Xianjie and Yuille, Alan},
  copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
  keywords  = {Computer Science - Computer Vision and Pattern Recognition},
  language  = {eng},
  title     = {Articulated Pose Estimation by a Graphical Model with Image Dependent Pairwise Relations},
  year      = {2014}
}

@misc{tatariants_2020,
  title     = {Challenges of Human Pose Estimation in AI-Powered Fitness Apps},
  url       = {https://www.infoq.com/articles/human-pose-estimation-ai-powered-fitness-apps/},
  journal   = {InfoQ},
  publisher = {InfoQ},
  author    = {Tatariants, Maksym},
  year      = {2020},
  month     = {Oct}
}

@inproceedings{BMVC.24.34,
  title     = {Background subtraction adapted to PTZ cameras by keypoint density estimation},
  author    = {Guillot, Constant and Taron, Maxime and Sayd, Patrick and Pham, Quoc Cuong and Tilmant, Christophe and Lavest, Jean-Marc},
  year      = {2010},
  pages     = {34.1--34.10},
  booktitle = {Proceedings of the British Machine Vision Conference},
  publisher = {BMVA Press},
  editors   = {Labrosse, Fr\'ed\'eric and Zwiggelaar, Reyer and Liu, Yonghuai and Tiddeman, Bernie},
  isbn      = {1-901725-40-5},
  note      = {doi:10.5244/C.24.34}
}

@article{CaoZhe2021ORM2,
  abstract  = {Realtime multi-person 2D pose estimation is a key component in enabling machines to have an understanding of people in images and videos. In this work, we present a realtime approach to detect the 2D pose of multiple people in an image. The proposed method uses a nonparametric representation, which we refer to as Part Affinity Fields (PAFs), to learn to associate body parts with individuals in the image. This bottom-up system achieves high accuracy and realtime performance, regardless of the number of people in the image. In previous work, PAFs and body part location estimation were refined simultaneously across training stages. We demonstrate that a PAF-only refinement rather than both PAF and body part location refinement results in a substantial increase in both runtime performance and accuracy. We also present the first combined body and foot keypoint detector, based on an internal annotated foot dataset that we have publicly released. We show that the combined detector not only reduces the inference time compared to running them sequentially, but also maintains the accuracy of each component individually. This work has culminated in the release of OpenPose, the first open-source realtime system for multi-person 2D pose detection, including body, foot, hand, and facial keypoints.},
  author    = {Cao, Zhe and Hidalgo, Gines and Simon, Tomas and Wei, Shih-En and Sheikh, Yaser},
  address   = {LOS ALAMITOS},
  issn      = {0162-8828},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  keywords  = {2D foot keypoint estimation ; 2D human pose estimation ; Computer Science ; Computer Science, Artificial Intelligence ; Detectors ; Engineering ; Engineering, Electrical & Electronic ; Kernel ; multiple person ; part affinity fields ; Pose estimation ; real-time ; Runtime ; Science & Technology ; Technology ; Training ; Two dimensional displays},
  language  = {eng},
  number    = {1},
  pages     = {172-186},
  publisher = {IEEE},
  title     = {OpenPose: Realtime Multi-Person 2D Pose Estimation Using Part Affinity Fields},
  volume    = {43},
  year      = {2021}
}

@article{KohliPushmeet2008SSaP,
  abstract  = {This paper presents a novel algorithm for performing integrated segmentation and 3D pose estimation of a human body from multiple views. Unlike other state of the art methods which focus on either segmentation or pose estimation individually, our approach tackles these two tasks together. Our method works by optimizing a cost function based on a Conditional Random Field (CRF). This has the advantage that all information in the image (edges, background and foreground appearances), as well as the prior information on the shape and pose of the subject can be combined and used in a Bayesian framework. Optimizing such a cost function would have been computationally infeasible. However, our recent research in dynamic graph cuts allows this to be done much more efficiently than before. We demonstrate the efficacy of our approach on challenging motion sequences. Although we target the human pose inference problem in the paper, our method is completely generic and can be used to segment and infer the pose of any rigid, deformable or articulated object.},
  author    = {Kohli, Pushmeet and Rihan, Jonathan and Bray, Matthieu and Torr, Philip H. S},
  address   = {Boston},
  copyright = {Springer Science+Business Media, LLC 2008},
  issn      = {0920-5691},
  journal   = {International journal of computer vision},
  keywords  = {Applied sciences ; Artificial intelligence ; Artificial Intelligence (incl. Robotics) ; Computer Imaging, Vision, Pattern Recognition and Graphics ; Computer Science ; Computer Science, Artificial Intelligence ; Computer science; control theory; systems ; Energy minimization ; Exact sciences and technology ; Image Processing and Computer Vision ; Pattern Recognition ; Pattern recognition. Digital image processing. Computational geometry ; Pose estimation ; Science & Technology ; Segmentation ; Studies ; Technology},
  language  = {eng},
  number    = {3},
  pages     = {285-298},
  publisher = {Springer US},
  title     = {Simultaneous Segmentation and Pose Estimation of Humans Using Dynamic Graph Cuts},
  volume    = {79},
  year      = {2008}
}

@article{DBLP:journals/corr/FangXL16,
  author     = {Haoshu Fang and
               Shuqin Xie and
               Cewu Lu},
  title      = {{RMPE:} Regional Multi-person Pose Estimation},
  journal    = {CoRR},
  volume     = {abs/1612.00137},
  year       = {2016},
  url        = {http://arxiv.org/abs/1612.00137},
  eprinttype = {arXiv},
  eprint     = {1612.00137},
  timestamp  = {Mon, 13 Aug 2018 16:48:28 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/FangXL16.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@misc{cv_2020,
  title   = {Deep Learning based human pose estimation with OpenCV},
  url     = {https://cv-tricks.com/pose-estimation/using-deep-learning-in-opencv/},
  journal = {CV},
  year    = {2020},
  month   = {Feb}
}

@inproceedings{BogoFederica2016KISA,
  abstract  = {We describe the first method to automatically estimate the 3D pose of the human body as well as its 3D shape from a single unconstrained image. We estimate a full 3D mesh and show that 2D joints alone carry a surprising amount of information about body shape. The problem is challenging because of the complexity of the human body, articulation, occlusion, clothing, lighting, and the inherent ambiguity in inferring 3D from 2D. To solve this, we first use a recently published CNN-based method, DeepCut, to predict (bottom-up) the 2D body joint locations. We then fit (top-down) a recently published statistical body shape model, called SMPL, to the 2D joints. We do so by minimizing an objective function that penalizes the error between the projected 3D model joints and detected 2D joints. Because SMPL captures correlations in human shape across the population, we are able to robustly fit it to very little data. We further leverage the 3D model to prevent solutions that cause interpenetration. We evaluate our method, SMPLify, on the Leeds Sports, HumanEva, and Human3.6M datasets, showing superior pose accuracy with respect to the state of the art.},
  author    = {Bogo, Federica and Kanazawa, Angjoo and Lassner, Christoph and Gehler, Peter and Romero, Javier and Black, Michael J},
  address   = {Cham},
  booktitle = {Computer Vision – ECCV 2016},
  copyright = {Springer International Publishing AG 2016},
  isbn      = {3319464531},
  issn      = {0302-9743},
  keywords  = {2D to 3D ; 3D body shape ; CNN ; Human pose},
  language  = {eng},
  pages     = {561-578},
  publisher = {Springer International Publishing},
  series    = {Lecture Notes in Computer Science},
  title     = {Keep It SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image},
  year      = {2016}
}
